# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
# å‚è€ƒï¼šhttps://github.com/ultralytics/ultralytics/blob/main/examples/YOLO-Interactive-Tracking-UI/interactive_tracker.py

from __future__ import annotations

import time
import os
import sys
import cv2
import yt_dlp

from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.plotting import Annotator, colors
import asyncio
import subprocess

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(root_dir)

from utils.select_camera import SelectCamera
from utils.common import load_yaml
from utils.stream_loader import LoadStreams
from utils.utils import check_requirements

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèªã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
#check_requirements('pytubefix>=6.5.2')
#check_requirements('yt-dlp')

class Tracker:
    def __init__(self, url=None):
        """è¨­å®šã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""

        # --- ç’°å¢ƒè¨­å®š ---
        # GPU (CUDA) ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ã€‚Trueã«ã™ã‚‹ã¨ã€å‡¦ç†é€Ÿåº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚
        enable_gpu = True
        # å®Ÿè¡Œç’°å¢ƒãŒMac PCã§ã‚ã‚‹ã‹ã‚’è¨­å®šã—ã¾ã™ã€‚
        mac_pc = True

        # --- ãƒ¢ãƒ‡ãƒ«è¨­å®š ---
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.ptï¼‰ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        model_path = os.path.join(os.path.dirname(__file__), 'models')
        # ä½¿ç”¨ã™ã‚‹YOLOãƒ¢ãƒ‡ãƒ«ã®åå‰ã€‚'n'ã¯ã€Œnanoã€ã‚’è¡¨ã™è»½é‡ã§é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
        model_name = "yolo12n.pt"
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å®Œå…¨ãªãƒ‘ã‚¹
        model_file = os.path.join(model_path, model_name)

        # --- å‹•ç”»ãƒ»è¡¨ç¤ºè¨­å®š ---
        # URLã®è¨­å®š
        self.url = url
        # LoadStreamsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
        self.load_streams = None
        # ç”»é¢å·¦ä¸Šã«ç¾åœ¨ã®FPSï¼ˆ1ç§’ã‚ãŸã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹ã€‚
        self.show_fps = False
        # æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¿¡é ¼åº¦ï¼ˆConfidence Scoreï¼‰ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹ã€‚
        self.show_conf = False
        # å‡¦ç†å¾Œã®æ˜ åƒã‚’å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã‹ã©ã†ã‹ã€‚
        self.save_video = False
        # å‡ºåŠ›å‹•ç”»ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        video_path = os.path.join(root_dir, 'output')
        # ä¿å­˜ã™ã‚‹å‹•ç”»ã®ãƒ•ã‚¡ã‚¤ãƒ«å
        video_name = "interactive_tracker_output.avi"
        # å‡ºåŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å®Œå…¨ãªãƒ‘ã‚¹
        self.video_output_path = os.path.join(video_path, video_name)

        # --- ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å¯¾è±¡ã¨YOLOãƒ¢ãƒ‡ãƒ«è¨­å®š ---
        # è¿½è·¡ã‚¯ãƒ©ã‚¹ãŒæ ¼ç´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚‹
        coco_data = load_yaml(os.path.join(model_path, 'coco.yaml'))
        class_data = coco_data['names']

        # è¿½è·¡ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç¨®é¡ã‚’ã‚¯ãƒ©ã‚¹IDã§æŒ‡å®šã—ã¾ã™ã€‚
        keys_to_extract = ['person', 'car']
        self.target_classes = [key for key, value in class_data.items() if value in keys_to_extract]

        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦èªè­˜ã™ã‚‹æœ€ä½é™ã®ä¿¡é ¼åº¦ã€‚ä½ã„ã¨èª¤æ¤œå‡ºãŒå¢—ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        self.conf = 0.3
        # IoU (Intersection over Union) ã®é–¾å€¤ã€‚ã“ã®å€¤ãŒä½ã„ã¨ã€é‡ãªã‚Šåˆã†ãƒœãƒƒã‚¯ã‚¹ãŒã‚ˆã‚Šå¤šãè¨±å®¹ã•ã‚Œã¾ã™ã€‚
        self.iou = 0.3
        # 1ã¤ã®ç”»åƒã§æ¤œå‡ºã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æœ€å¤§æ•°ã€‚
        self.max_det = 20

        # --- ãƒˆãƒ©ãƒƒã‚«ãƒ¼è¨­å®š ---
        # ä½¿ç”¨ã™ã‚‹ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®ç¨®é¡ã‚’æŒ‡å®š
        self.tracker = "bytetrack.yaml"
        # ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®å‹•ä½œã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ãŸã‚ã®å¼•æ•°ã€‚
        self.track_args = {
            # ãƒ•ãƒ¬ãƒ¼ãƒ å±¥æ­´ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã—ã¦ä¿æŒã—ã€ç¶™ç¶šçš„ãªè¿½è·¡ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
            "persist": True,
            # ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹ã€‚
            "verbose": False,
        }

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ˜ åƒãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚
        self.window_name = "Ultralytics YOLO Interactive Tracking"

        LOGGER.info("ğŸš€ Initializing model...")
        if enable_gpu:
            LOGGER.info("Using GPU...")
            self.model = YOLO(model_file)
            if mac_pc:
                self.model.to("mps")
            else:
                self.model.to("cuda")
        else:
            LOGGER.info("Using CPU...")
            self.model = YOLO(model_file, task="detect")

        self.classes = self.model.names  # Store model class names

        # URLãŒã‚ã‚‹ã‹ãªã„ã‹ã§å‡¦ç†ã‚’å¤‰ãˆã‚‹
        self.setup_video(url) if url else self.setup_camera()
        # ãƒ“ãƒ‡ã‚ªãƒ©ã‚¤ã‚¿ãƒ¼ã®è¨­å®š
        self.setup_video_writer()

    def setup_camera(self):
        """
        ã‚«ãƒ¡ãƒ©ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚
        """
        # ã‚«ãƒ¡ãƒ©ã®é¸æŠ
        select_camera = SelectCamera()
        camera_index = select_camera.get_camera_index()
        self.cap = cv2.VideoCapture(camera_index)

    def setup_video(self, url: str):
        """YouTubeå‹•ç”»ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã€‚"""
        # æ—¢å­˜ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã‚ã‚Œã°ã€ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¦ã‹ã‚‰å†åˆæœŸåŒ–ã™ã‚‹
        if self.load_streams:
            self.load_streams.close()
        self.load_streams = LoadStreams(url)
        self.cap = self.load_streams.caps[0]
        if not self.cap.isOpened():
            raise RuntimeError("å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        LOGGER.info(f"âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚½ãƒ¼ã‚¹ã‹ã‚‰å‹•ç”»ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {url}")

    def setup_video_writer(self):
        """
        ãƒ“ãƒ‡ã‚ªãƒ©ã‚¤ã‚¿ãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚
        """
        if not self.cap.isOpened():
            LOGGER.error("ã‚«ãƒ¡ãƒ©ãŒé–‹ã‹ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ“ãƒ‡ã‚ªãƒ©ã‚¤ã‚¿ãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ãã¾ã›ã‚“ã€‚")
            return
        # Initialize video writer
        self.vw = None
        if self.save_video:
            self.w, self.h, self.fps = (int(self.cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
            self.vw = cv2.VideoWriter(self.video_output_path, cv2.VideoWriter_fourcc(*"mp4v"), self.fps, (self.w, self.h))

        self.selected_object_id = None
        selected_bbox = None
        selected_center = None

    def release_capture(self):
        self.cap.release()
        if self.save_video and self.vw is not None:
            self.vw.release()
        cv2.destroyAllWindows()

    def get_center(self, x1: int, y1: int, x2: int, y2: int) -> tuple[int, int]:
        """
        Calculate the center point of a bounding box.

        Args:
            x1 (int): Top-left X coordinate.
            y1 (int): Top-left Y coordinate.
            x2 (int): Bottom-right X coordinate.
            y2 (int): Bottom-right Y coordinate.

        Returns:
            center_x (int): X-coordinate of the center point.
            center_y (int): Y-coordinate of the center point.
        """
        return (x1 + x2) // 2, (y1 + y2) // 2


    def extend_line_from_edge(self, mid_x: int, mid_y: int, direction: str, img_shape: tuple[int, int, int]) -> tuple[int, int]:
        """
        Calculate the endpoint to extend a line from the center toward an image edge.

        Args:
            mid_x (int): X-coordinate of the midpoint.
            mid_y (int): Y-coordinate of the midpoint.
            direction (str): Direction to extend ('left', 'right', 'up', 'down').
            img_shape (tuple[int, int, int]): Image shape in (height, width, channels).

        Returns:
            end_x (int): X-coordinate of the endpoint.
            end_y (int): Y-coordinate of the endpoint.
        """
        h, w = img_shape[:2]
        if direction == "left":
            return 0, mid_y
        elif direction == "right":
            return w - 1, mid_y
        elif direction == "up":
            return mid_x, 0
        elif direction == "down":
            return mid_x, h - 1
        else:
            return mid_x, mid_y

    def draw_tracking_scope(self, im, bbox: tuple, color: tuple) -> None:
        """
        Draw tracking scope lines extending from the bounding box to image edges.

        Args:
            im (np.ndarray): Image array to draw on.
            bbox (tuple): Bounding box coordinates (x1, y1, x2, y2).
            color (tuple): Color in BGR format for drawing.
        """
        x1, y1, x2, y2 = bbox
        mid_top = ((x1 + x2) // 2, y1)
        mid_bottom = ((x1 + x2) // 2, y2)
        mid_left = (x1, (y1 + y2) // 2)
        mid_right = (x2, (y1 + y2) // 2)
        cv2.line(im, mid_top, self.extend_line_from_edge(*mid_top, "up", im.shape), color, 2)
        cv2.line(im, mid_bottom, self.extend_line_from_edge(*mid_bottom, "down", im.shape), color, 2)
        cv2.line(im, mid_left, self.extend_line_from_edge(*mid_left, "left", im.shape), color, 2)
        cv2.line(im, mid_right, self.extend_line_from_edge(*mid_right, "right", im.shape), color, 2)

    def click_event(self, event: int, x: int, y: int, flags: int, param) -> None:
        """
        Handle mouse click events to select an object for focused tracking.

        Args:
            event (int): OpenCV mouse event type.
            x (int): X-coordinate of the mouse event.
            y (int): Y-coordinate of the mouse event.
            flags (int): Any relevant flags passed by OpenCV.
            param (Any): Additional parameters (not used).
        """
        if event == cv2.EVENT_LBUTTONDOWN:
            detections = self.results[0].boxes.data if self.results[0].boxes is not None else []
            if detections is not None:
                min_area = float("inf")
                best_match = None
                for track in detections:
                    track = track.tolist()
                    if len(track) >= 6:
                        x1, y1, x2, y2 = map(int, track[:4])
                        if x1 <= x <= x2 and y1 <= y <= y2:
                            area = (x2 - x1) * (y2 - y1)
                            if area < min_area:
                                class_id = int(track[-1])
                                track_id = int(track[4]) if len(track) == 7 else -1
                                min_area = area
                                best_match = (track_id, self.model.names[class_id])
                if best_match:
                    self.selected_object_id, label = best_match
                    print(f"ğŸ”µ TRACKING STARTED: {label} (ID {self.selected_object_id})")

    def track(self, im=None, raw=False, fps_counter=0, fps_timer=time.time(), fps_display=0, server=False):
        if self.url and im is None:
            if self.load_streams is None:
                self.setup_video(self.url)
            # YouTubeå‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            _, images, _ = next(self.load_streams)
            if images is None:
                return
            elif raw:
                return images[0]
            else:
                im = images[0]
        elif im is None:
          success, im = self.cap.read()
          if not success:
              return

        # ç‰©ä½“è¿½è·¡ã¨æç”»
        self.results = self.model.track(im, conf=self.conf, iou=self.iou, max_det=self.max_det, tracker=self.tracker, classes=self.target_classes, **self.track_args)
        annotator = Annotator(im)
        detections = self.results[0].boxes.data if self.results[0].boxes is not None else []
        detected_objects = []

        for track in detections:
            track = track.tolist()
            if len(track) < 6:
                continue
            x1, y1, x2, y2 = map(int, track[:4])
            class_id = int(track[6]) if len(track) >= 7 else int(track[5])
            track_id = int(track[4]) if len(track) == 7 else -1
            color = colors(track_id, True)
            txt_color = annotator.get_txt_color(color)
            label = f"{self.classes[class_id]} ID {track_id}" + (f" ({float(track[5]):.2f})" if self.show_conf else "")
            if track_id == self.selected_object_id:
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¿½è·¡å¯¾è±¡ã®æç”»
                self.draw_tracking_scope(im, (x1, y1, x2, y2), color)
                center = self.get_center(x1, y1, x2, y2)
                cv2.circle(im, center, 6, color, -1)

                # Pulsing circle for attention
                pulse_radius = 8 + int(4 * abs(time.time() % 1 - 0.5))
                cv2.circle(im, center, pulse_radius, color, 2)

                annotator.box_label([x1, y1, x2, y2], label=f"ACTIVE: TRACK {track_id}", color=color)
            else:
                # ãã®ä»–ã®ç‰©ä½“ã®æç”»
                for i in range(x1, x2, 10):
                    cv2.line(im, (i, y1), (i + 5, y1), color, 3)
                    cv2.line(im, (i, y2), (i + 5, y2), color, 3)
                for i in range(y1, y2, 10):
                    cv2.line(im, (x1, i), (x1, i + 5), color, 3)
                    cv2.line(im, (x2, i), (x2, i + 5), color, 3)
                # Draw label text with background
                (tw, th), bl = cv2.getTextSize(label, 0, 0.7, 2)
                cv2.rectangle(im, (x1 + 5 - 5, y1 + 20 - th - 5), (x1 + 5 + tw + 5, y1 + 20 + bl), color, -1)
                cv2.putText(im, label, (x1 + 5, y1 + 20), 0, 0.7, txt_color, 1, cv2.LINE_AA)

        if self.show_fps:
            fps_counter += 1
            if time.time() - fps_timer >= 1.0:
                fps_display = fps_counter
                fps_counter = 0
                fps_timer = time.time()

            # Draw FPS text with background
            fps_text = f"FPS: {fps_display}"
            cv2.putText(im, fps_text, (10, 25), 0, 0.7, (255, 255, 255), 1)
            (tw, th), bl = cv2.getTextSize(fps_text, 0, 0.7, 2)
            cv2.rectangle(im, (10 - 5, 25 - th - 5), (10 + tw + 5, 25 + bl), (255, 255, 255), -1)
            cv2.putText(im, fps_text, (10, 25), 0, 0.7, (104, 31, 17), 1, cv2.LINE_AA)

        # ã‚µãƒ¼ãƒãƒ¼å´ã®ã¿ã®å‡¦ç†ã®å ´åˆ
        if server:
            cv2.imshow(self.window_name, im)
            if self.save_video and self.vw is not None:
                self.vw.write(im)
            # Terminal logging
            LOGGER.info(f"ğŸŸ¡ DETECTED {len(detections)} OBJECT(S): {' | '.join(detected_objects)}")

            key = cv2.waitKey(1) & 0xFF
            if key == ord("q"):
                return
            elif key == ord("c"):
                LOGGER.info("ğŸŸ¢ TRACKING RESET")
                self.selected_object_id = None
        else:
            return im

    def track_safe(self, im=None, raw=False, fps_counter=0, fps_timer=time.time(), fps_display=0, server=False):
        while True:
            try:
                im = self.track(im, raw=raw, fps_counter=fps_counter, fps_timer=fps_timer, fps_display=fps_display, server=server)
                return im
            except StopIteration:
                self.load_streams = None
                continue 
            except Exception as e:
                LOGGER.error(f"Error during tracking: {e}")
                assert self.url, "å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    def exec(self, im=None, server=False, raw=False):
        if server:
            cv2.namedWindow(self.window_name)
            cv2.setMouseCallback(self.window_name, self.click_event)

        while self.cap.isOpened():
            if self.url:
                frame = self.track_safe(raw=raw, server=server)
            elif raw:
                _, frame = self.cap.read()
            else:
                frame = self.track(im, server=server)
            # JPEGå½¢å¼ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            _, buffer = cv2.imencode('.jpg', frame)
            frame_bytes = buffer.tobytes()

            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’yield
            yield (
                b'--frame\r\n'
                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n'
            )
        self.release_capture()

    async def ws_exec(self, im=None, raw=False):
        while self.cap.isOpened():
            if self.url:
                frame = self.track_safe(raw=raw)
            elif raw:
                _, frame = self.cap.read()
            else:
                frame = self.track(im)
            # JPEGå½¢å¼ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            _, buffer = cv2.imencode('.jpg', frame)
            frame_bytes = buffer.tobytes()

            # éåŒæœŸã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’yield
            yield frame_bytes

            await asyncio.sleep(0.01)

        self.release_capture()
if __name__ == '__main__':
    tracker = Tracker()
    tracker.exec()
    sys.exit(0)